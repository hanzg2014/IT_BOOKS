{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow for Stylenet/NeuralStyle\n",
    "---------------------------------------\n",
    "\n",
    "We use two images, an original image and a style image and try to make the original image in the style of the style image.\n",
    "\n",
    "Reference paper:\n",
    "https://arxiv.org/abs/1508.06576\n",
    "\n",
    "Need to download the model 'imagenet-vgg-verydee-19.mat' from:\n",
    "http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
    "\n",
    "We start by loading the necessary libraries and clearing any prior computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image Files\n",
    "original_image_file = 'temp/book_cover.jpg'\n",
    "style_image_file = 'temp/starry_night.jpg'\n",
    "\n",
    "# Saved VGG Network path\n",
    "vgg_path = '/home/nick/Documents/tensorflow/vgg_19_models/imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "# Default Arguments\n",
    "original_image_weight = 0.0005\n",
    "style_image_weight = 0.02\n",
    "regularization_weight = 50.0\n",
    "learning_rate = 0.1\n",
    "generations = 500\n",
    "output_generations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in images\n",
    "original_image = scipy.misc.imread(original_image_file)\n",
    "style_image = scipy.misc.imread(style_image_file)\n",
    "\n",
    "# Get shape of target and make the style image the same\n",
    "target_shape = original_image.shape\n",
    "style_image = scipy.misc.imresize(style_image, target_shape[1] / style_image.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VGG-19 Layer Setup\n",
    "# From paper\n",
    "vgg_layers = ['conv1_1', 'relu1_1',\n",
    "              'conv1_2', 'relu1_2', 'pool1',\n",
    "              'conv2_1', 'relu2_1',\n",
    "              'conv2_2', 'relu2_2', 'pool2',\n",
    "              'conv3_1', 'relu3_1',\n",
    "              'conv3_2', 'relu3_2',\n",
    "              'conv3_3', 'relu3_3',\n",
    "              'conv3_4', 'relu3_4', 'pool3',\n",
    "              'conv4_1', 'relu4_1',\n",
    "              'conv4_2', 'relu4_2',\n",
    "              'conv4_3', 'relu4_3',\n",
    "              'conv4_4', 'relu4_4', 'pool4',\n",
    "              'conv5_1', 'relu5_1',\n",
    "              'conv5_2', 'relu5_2',\n",
    "              'conv5_3', 'relu5_3',\n",
    "              'conv5_4', 'relu5_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract weights and matrix means\n",
    "def extract_net_info(path_to_params):\n",
    "    vgg_data = scipy.io.loadmat(path_to_params)\n",
    "    normalization_matrix = vgg_data['normalization'][0][0][0]\n",
    "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
    "    network_weights = vgg_data['layers'][0]\n",
    "    return(mat_mean, network_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the VGG-19 Network\n",
    "def vgg_network(network_weights, init_image):\n",
    "    network = {}\n",
    "    image = init_image\n",
    "\n",
    "    for i, layer in enumerate(vgg_layers):\n",
    "        if layer[1] == 'c':\n",
    "            weights, bias = network_weights[i][0][0][0][0]\n",
    "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
    "            image = tf.nn.bias_add(conv_layer, bias)\n",
    "        elif layer[1] == 'r':\n",
    "            image = tf.nn.relu(image)\n",
    "        else:\n",
    "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
    "        network[layer] = image\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we define which layers apply to the original or style image\n",
    "original_layer = 'relu4_2'\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get network parameters\n",
    "normalization_mean, network_weights = extract_net_info(vgg_path)\n",
    "\n",
    "shape = (1,) + original_image.shape\n",
    "style_shape = (1,) + style_image.shape\n",
    "original_features = {}\n",
    "style_features = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get network parameters\n",
    "image = tf.placeholder('float', shape=shape)\n",
    "vgg_net = vgg_network(network_weights, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize original image\n",
    "original_minus_mean = original_image - normalization_mean\n",
    "original_norm = np.array([original_minus_mean])\n",
    "original_features[original_layer] = sess.run(vgg_net[original_layer], feed_dict={image: original_norm})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get style image network\n",
    "image = tf.placeholder('float', shape=style_shape)\n",
    "vgg_net = vgg_network(network_weights, image)\n",
    "style_minus_mean = style_image - normalization_mean\n",
    "style_norm = np.array([style_minus_mean])\n",
    "\n",
    "for layer in style_layers:\n",
    "    layer_output = sess.run(vgg_net[layer], feed_dict={image: style_norm})\n",
    "    layer_output = np.reshape(layer_output, (-1, layer_output.shape[3]))\n",
    "    style_gram_matrix = np.matmul(layer_output.T, layer_output) / layer_output.size\n",
    "    style_features[layer] = style_gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make Combined Image\n",
    "initial = tf.random_normal(shape) * 0.05\n",
    "image = tf.Variable(initial)\n",
    "vgg_net = vgg_network(network_weights, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: relu1_1, Loss: 15014316.0\n",
      "Layer: relu2_1, Loss: 15014316.0\n",
      "Layer: relu3_1, Loss: 15014316.0\n",
      "Layer: relu4_1, Loss: 15014316.0\n",
      "Layer: relu5_1, Loss: 15014316.0\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "original_loss = original_image_weight * (2 * tf.nn.l2_loss(vgg_net[original_layer] - original_features[original_layer]) /\n",
    "                original_features[original_layer].size)\n",
    "\n",
    "# Loss from Style Image\n",
    "style_loss = 0\n",
    "style_losses = []\n",
    "for style_layer in style_layers:\n",
    "    layer = vgg_net[style_layer]\n",
    "    feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "    size = height * width * channels\n",
    "    features = tf.reshape(layer, (-1, channels))\n",
    "    style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
    "    style_expected = style_features[style_layer]\n",
    "    #style_temp_loss = sess.run(2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)\n",
    "    #print('Layer: {}, Loss: {}'.format(style_layer, style_temp_loss))\n",
    "    style_losses.append(2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)\n",
    "style_loss += style_image_weight * tf.reduce_sum(style_losses)\n",
    "\n",
    "# To Smooth the resuts, we add in total variation loss       \n",
    "total_var_x = sess.run(tf.reduce_prod(image[:,1:,:,:].get_shape()))\n",
    "total_var_y = sess.run(tf.reduce_prod(image[:,:,1:,:].get_shape()))\n",
    "first_term = regularization_weight * 2\n",
    "second_term_numerator = tf.nn.l2_loss(image[:,1:,:,:] - image[:,:shape[1]-1,:,:])\n",
    "second_term = second_term_numerator / total_var_y\n",
    "third_term = (tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:shape[2]-1,:]) / total_var_x)\n",
    "total_variation_loss = first_term * (second_term + third_term)\n",
    "\n",
    "# Combined Loss\n",
    "loss = original_loss + style_loss + total_variation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 492.43005371,  458.42831421,  576.28674316]]]], dtype=float32)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 492.43005371,  458.42831421,  576.28674316]], dtype=float32)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  80829.1171875,   75247.9609375,   94593.6328125],\n",
       "       [  75247.9609375,   70052.171875 ,   88062.0546875],\n",
       "       [  94593.6328125,   88062.0546875,  110702.1328125]], dtype=float32)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.matmul(tf.transpose(features), features) / size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3354.70092773,  3552.03027344,  4014.83984375],\n",
       "       [ 3552.03027344,  3760.96704102,  4250.99951172],\n",
       "       [ 4014.83984375,  4250.99951172,  4804.88085938]], dtype=float32)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_layer = 'relu2_1'\n",
    "layer = vgg_net[style_layer]\n",
    "feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "size = height * width * channels\n",
    "features = tf.reshape(layer, (-1, channels))\n",
    "style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
    "style_expected = style_features[style_layer]\n",
    "style_losses.append(2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 100.72416687,  106.6307373 ,  120.61589813]]]], dtype=float32)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2249.29736328,  2318.18383789,  2775.89428711],\n",
       "       [ 2318.18383789,  2419.2878418 ,  2915.45068359],\n",
       "       [ 2775.89428711,  2915.45068359,  3578.22509766]], dtype=float32)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1970.56860352,  2058.08105469,  2480.35449219],\n",
       "       [ 2058.08105469,  2149.82885742,  2589.22558594],\n",
       "       [ 2480.35449219,  2589.22558594,  3127.53442383]], dtype=float32)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(style_gram_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  71.19725037,   73.60102081,   92.87404633],\n",
       "       [  65.66284943,   67.88374329,   85.64056396],\n",
       "       [  70.32759857,   72.70740509,   91.70826721],\n",
       "       [  68.9703064 ,   71.29055023,   89.97322845],\n",
       "       [ 100.72416687,  105.67219543,  120.61589813],\n",
       "       [  68.57144928,   70.89800262,   89.44815826],\n",
       "       [  63.51005936,   65.65606689,   82.81027985],\n",
       "       [  99.80554199,  106.6307373 ,  119.45858002],\n",
       "       [ 100.27510834,  106.16234589,  120.04843903],\n",
       "       [  64.67858124,   66.85785675,   84.34563446],\n",
       "       [  65.95037079,   68.1950531 ,   85.99183655],\n",
       "       [  66.53562927,   68.81031799,   86.76571655]], dtype=float32)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(12), Dimension(3)])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Layer: relu1_1 -------\n",
      "[[[[ 0.08247361  0.04152144  0.10092877]\n",
      "   [ 0.08947127  0.08691224  0.05242458]\n",
      "   [ 0.14437069  0.07853114  0.07240488]\n",
      "   ..., \n",
      "   [ 0.1007843   0.09986139  0.12209319]\n",
      "   [ 0.05227378  0.10274027  0.09586678]\n",
      "   [ 0.02098998  0.03495882  0.01644966]]\n",
      "\n",
      "  [[ 0.04201204  0.09918579  0.10414404]\n",
      "   [ 0.11072802  0.01286861  0.12579992]\n",
      "   [ 0.11812787  0.07101136  0.07419724]\n",
      "   ..., \n",
      "   [ 0.06674157  0.07611842  0.07811055]\n",
      "   [ 0.1128375   0.09529858  0.05741931]\n",
      "   [ 0.05386398  0.10804675  0.02621546]]\n",
      "\n",
      "  [[ 0.08730088  0.07363851  0.08691902]\n",
      "   [ 0.06481196  0.03303457  0.04696261]\n",
      "   [ 0.06705463  0.07307769  0.08912132]\n",
      "   ..., \n",
      "   [ 0.06230537  0.07266171  0.11867781]\n",
      "   [ 0.08606199  0.04909804  0.1145003 ]\n",
      "   [ 0.10217204  0.07850321  0.0741777 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.07669023  0.13257091  0.11716817]\n",
      "   [ 0.05869968  0.09233315  0.10477214]\n",
      "   [ 0.06873928  0.13356456  0.07592094]\n",
      "   ..., \n",
      "   [ 0.11683203  0.08175176  0.06290048]\n",
      "   [ 0.06680899  0.09997979  0.06474196]\n",
      "   [ 0.09910869  0.06390733  0.0703821 ]]\n",
      "\n",
      "  [[ 0.07530364  0.10443608  0.07342286]\n",
      "   [ 0.11925755  0.06976316  0.11698323]\n",
      "   [ 0.07412194  0.08384395  0.0541024 ]\n",
      "   ..., \n",
      "   [ 0.05200339  0.06840221  0.07072043]\n",
      "   [ 0.06880333  0.09493216  0.06655537]\n",
      "   [ 0.01772987  0.10226523  0.11237977]]\n",
      "\n",
      "  [[ 0.09139587  0.09695249  0.11416103]\n",
      "   [ 0.05663698  0.09194823  0.07927536]\n",
      "   [ 0.04019465  0.06481113  0.00630139]\n",
      "   ..., \n",
      "   [ 0.04468096  0.07213445  0.08445483]\n",
      "   [ 0.08850736  0.0420691   0.10435742]\n",
      "   [ 0.05786019  0.06173276  0.04724393]]]]\n",
      "28290\n",
      "\n",
      "-------Layer: relu2_1 -------\n",
      "[[[[  27.0633316    20.85456467   23.7694931 ]\n",
      "   [  54.7818222    39.98239899   53.99686432]\n",
      "   [  38.0798111     9.07472992   10.89078712]\n",
      "   [  45.82107544    2.75207734    7.85407257]]\n",
      "\n",
      "  [[   6.78560781   56.39316177  576.28674316]\n",
      "   [  45.7634964    12.79589462   39.74602509]\n",
      "   [  44.10842514   16.03715134   19.76008987]\n",
      "   [  51.16899109   20.1850853    44.21724701]]\n",
      "\n",
      "  [[ 492.43005371   26.22451591   46.66320038]\n",
      "   [  18.34512329   17.57855415    8.63122845]\n",
      "   [  36.61977386  458.42831421    7.19512463]\n",
      "   [  50.83989716    4.48850727   33.14919662]]]]\n",
      "36\n",
      "\n",
      "-------Layer: relu3_1 -------\n",
      "[[[[ 492.43005371  458.42831421  576.28674316]]]]\n",
      "3\n",
      "\n",
      "-------Layer: relu4_1 -------\n",
      "[[[[ 492.43005371  458.42831421  576.28674316]]]]\n",
      "3\n",
      "\n",
      "-------Layer: relu5_1 -------\n",
      "[[[[ 492.43005371  458.42831421  576.28674316]]]]\n",
      "3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for style_layer in style_layers:\n",
    "    print('-------Layer: {} -------'.format(style_layer))\n",
    "    layer = vgg_net[style_layer]\n",
    "    print(sess.run(layer))\n",
    "    feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "    size = height * width * channels\n",
    "    print(size)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 50.61659241,  76.2098999 ,  65.95883179]]]], dtype=float32)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3216602e+09"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537399.12"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(style_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3211228e+09"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(total_variation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.958351"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(original_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446946 446550\n"
     ]
    }
   ],
   "source": [
    "print(total_var_y, total_var_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare Optimization Algorithm\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# Initialize Variables and start Training\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 100 out of 500\n",
      "Generation 200 out of 500\n",
      "Generation 300 out of 500\n",
      "Generation 400 out of 500\n",
      "Generation 500 out of 500\n"
     ]
    }
   ],
   "source": [
    "# Declare Optimization Algorithm\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# Initialize Variables and start Training\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(generations):\n",
    "    \n",
    "    sess.run(train_step)\n",
    "\n",
    "    # Print update and save temporary output\n",
    "    if (i+1) % output_generations == 0:\n",
    "        print('Generation {} out of {}'.format(i + 1, generations))\n",
    "        image_eval = sess.run(image)\n",
    "        best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "        output_file = 'temp_output_{}.jpg'.format(i)\n",
    "        scipy.misc.imsave(output_file, best_image_add_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.04712168,  0.03435499,  0.02002956],\n",
       "         [-0.03250763,  0.00673179, -0.0147724 ],\n",
       "         [ 0.02896713, -0.00411567,  0.08262652],\n",
       "         ..., \n",
       "         [-0.1370527 , -0.01855541,  0.00446089],\n",
       "         [-0.06849232, -0.04610289,  0.01645049],\n",
       "         [-0.05741588,  0.01752681, -0.03479913]],\n",
       "\n",
       "        [[-0.08423983,  0.02016895, -0.04017523],\n",
       "         [ 0.02667994, -0.01776898, -0.04314912],\n",
       "         [-0.01220408,  0.01039219,  0.10092995],\n",
       "         ..., \n",
       "         [ 0.02354718,  0.00214768,  0.03652928],\n",
       "         [ 0.00175504, -0.02626217, -0.01919887],\n",
       "         [ 0.02099239,  0.02947534, -0.02159922]],\n",
       "\n",
       "        [[ 0.03742211,  0.03676733,  0.03237842],\n",
       "         [-0.05757976,  0.01306623, -0.03120742],\n",
       "         [ 0.01698635,  0.04152049,  0.05278337],\n",
       "         ..., \n",
       "         [ 0.00586959,  0.06157336,  0.01941444],\n",
       "         [ 0.00551952, -0.04034816, -0.06150487],\n",
       "         [-0.04799243,  0.0349594 , -0.10273691]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.01167455, -0.08570861, -0.05203295],\n",
       "         [-0.01180731, -0.03013614,  0.03407335],\n",
       "         [ 0.01468409, -0.04751442,  0.07342485],\n",
       "         ..., \n",
       "         [ 0.01118292, -0.02083848,  0.06308033],\n",
       "         [-0.02579049, -0.03010971,  0.03168033],\n",
       "         [ 0.01772941,  0.10226656,  0.03783409]],\n",
       "\n",
       "        [[ 0.05780045, -0.01873782, -0.05291304],\n",
       "         [ 0.09139726,  0.08451898,  0.11416516],\n",
       "         [ 0.04608795, -0.04752794, -0.00850722],\n",
       "         ..., \n",
       "         [ 0.02304918,  0.01548453, -0.02873957],\n",
       "         [ 0.0578636 , -0.03226628,  0.03930647],\n",
       "         [-0.01696256,  0.03365666,  0.04724168]],\n",
       "\n",
       "        [[-0.00476588,  0.09695164,  0.04498148],\n",
       "         [-0.0106004 , -0.01369812,  0.00789222],\n",
       "         [-0.05575656,  0.0717017 , -0.02563389],\n",
       "         ..., \n",
       "         [ 0.08850884,  0.02500135, -0.03303704],\n",
       "         [-0.03353019,  0.01063005, -0.04499141],\n",
       "         [ 0.02197913,  0.06173124,  0.02030567]]]], dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-134365.08"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_min(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.2099"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.reduce_max(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save final image\n",
    "image_eval = sess.run(image)\n",
    "best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "output_file = 'final_output.jpg'\n",
    "scipy.misc.imsave(output_file, best_image_add_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
